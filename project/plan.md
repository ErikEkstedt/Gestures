# Plan

Environment with: 
* [ ] Clean Reacher with visible target dots. Small state space.
* [ ] Clean SocialReacher state space only implementation.
* [ ] SocialHumanoidHlaf??

Reward
* [ ] Try several runs with reward function
* [ ] Show/record best test score and relate to training data.

Train
* [ ] Clean training loop.
* [ ] Change environmnet easy (now my environments should not change anymore)

Test
* [ ] Set up a test script that utilizes state_target approximation

Values
* [ ] The value/policy loss always depends on size of steps.
	* [ ] Normalize this data.
* [ ] A specific reward function will yield the same reward for the same DoF
	* Baseline (play with random agent average)
	* [ ] SocialReacher
	* [ ] SocialHumanoid
	* [ ] SocialHumanoidHalf?

